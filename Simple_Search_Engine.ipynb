{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Search Engine**"
      ],
      "metadata": {
        "id": "H9SP0HKJSDO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Working of Simple Search Engine**\n",
        "\n",
        "* The Simple Search Engine operates on a straightforward keyword-based search methodology. It utilizes the PyPDF2 library in Python to extract text content from uploaded PDF files. Once a PDF is uploaded, the search engine reads through each page, preprocesses the text, and indexes it based on stemmed tokens.\n",
        "\n",
        "* When a user submits a search query, the search engine identifies relevant documents by finding the intersection of all pages containing the queried keywords. This process involves preprocessing the query, tokenizing it into individual terms, and identifying the stemmed forms of these terms.\n",
        "\n",
        "* The search engine then looks up each stemmed term in its index to retrieve a list of document IDs where the term appears. By taking the intersection of these sets of document IDs for all query terms, the engine determines the pages that contain all the keywords provided by the user.\n",
        "\n",
        "* Finally, the search engine presents the text content of these identified pages to the user, allowing them to access the relevant information they are looking for. This simple yet effective approach provides users with a quick and intuitive way to search for specific information within PDF documents."
      ],
      "metadata": {
        "id": "UNaJP6_0J_TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "id": "9SA7DJxtji_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f20e0e-f487-4124-ea64-2067aada5d27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import PyPDF2\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "class SimpleSearchEngine:\n",
        "    def __init__(self):\n",
        "        self.index = {}  #  Initialize an empty dictionary to store the index.\n",
        "        self.documents = {}  # Store document text by document ID\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.stemmer = PorterStemmer()\n",
        "\n",
        "    def preprocess_text(self, text):  # Define a method to preprocess text by converting it to lowercase and removing non-alphanumeric characters\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "        text = re.sub(' +', ' ', text)\n",
        "        return text\n",
        "\n",
        "    def stem_tokens(self, tokens): # Define a method to stem tokens using the Porter Stemmer.\n",
        "        return [self.stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    def index_pdf(self, pdf_file): # Define a method to index a PDF file by extracting text from each page.\n",
        "        with open(pdf_file, 'rb') as file: # Open the PDF file\n",
        "            reader = PyPDF2.PdfReader(file)   # Create a PDF reader object.\n",
        "\n",
        "            for page_num in range(len(reader.pages)): # Iterate through each page of the PDF.\n",
        "                page_text = reader.pages[page_num].extract_text() # Extract text from the current page.\n",
        "                processed_text = self.preprocess_text(page_text) # Preprocess the extracted text.\n",
        "                doc_id = f\"{pdf_file}_page_{page_num}\"  # Generate unique document ID\n",
        "                self.documents[doc_id] = page_text  # Store the document text in self.document\n",
        "                self.index_document(doc_id, processed_text) # Index the document by calling the index_document method.\n",
        "\n",
        "        # Update TF-IDF vectorizer\n",
        "        self.vectorizer.fit(list(self.documents.values()))\n",
        "\n",
        "    def index_document(self, doc_id, text): # Define a method to index a document by splitting text into tokens, stemming them, and updating the index.\n",
        "        tokens = text.split()\n",
        "        stemmed_tokens = self.stem_tokens(tokens)\n",
        "        for token in stemmed_tokens:\n",
        "            if token not in self.index:\n",
        "                self.index[token] = []\n",
        "            self.index[token].append(doc_id)\n",
        "\n",
        "    def get_document_text(self, doc_id):\n",
        "        return self.documents.get(doc_id, None)\n",
        "\n",
        "    def search(self, query): # Define method for Search query\n",
        "        processed_query = self.preprocess_text(query)\n",
        "        query_vector = self.vectorizer.transform([processed_query])\n",
        "        query_tokens = processed_query.split()\n",
        "        stemmed_query_tokens = self.stem_tokens(query_tokens)\n",
        "        result_set = set()\n",
        "        for token in stemmed_query_tokens:\n",
        "            if token in self.index:\n",
        "                if not result_set:\n",
        "                    result_set.update(self.index[token])\n",
        "                else:\n",
        "                    result_set.intersection_update(self.index[token])\n",
        "        return [self.get_document_text(doc_id) for doc_id in result_set]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QomlSC5zwuRk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passing Necessary Parameters\n",
        "\n",
        "search_engine = SimpleSearchEngine() # calling simplesearchengine\n",
        "pdf_file = '/content/Projects.pdf' # passing our PDF\n",
        "search_engine.index_pdf(pdf_file) # passing it to index_pdf to get indexed suitable for searching."
      ],
      "metadata": {
        "id": "WzbAh7hqN7w2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying in Simple Search Engine\n",
        "\n",
        "query = \"python\" # Passing Query\n",
        "results = search_engine.search(query)\n",
        "\n",
        "for result in results: # For Printing all pages found by the search result\n",
        "    print(\"Search result:\")\n",
        "    print(result)\n",
        "\n",
        "# As python in present in project 1,2,3 and 4 it returns all the pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFF_AcEmwz7o",
        "outputId": "9f36029e-b30d-4aac-c2fd-b9948af8e72e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search result:\n",
            "4 | P a g e  \n",
            " \n",
            "Project 4(Four)  \n",
            "Simple Search Engine  \n",
            " \n",
            "• The Simple Search Engine operates on a straightforward keyword -based \n",
            "search methodology. It utilizes the PyPDF2 library in Python to extract text \n",
            "content from uploaded PDF files. Once a PDF is uploaded, the search engine \n",
            "reads through each page, preprocess es the text, and indexes it based on \n",
            "stemmed tokens.  \n",
            "• When a user submits a search query, the search engine identifies relevant \n",
            "documents by finding the intersection of all pages containing the queried \n",
            "keywords. This process involves preprocessing the query, tokenizing it into \n",
            "individual terms, and identifyin g the stemmed forms of these terms.  \n",
            "• The search engine then looks up each stemmed term in its index to retrieve a \n",
            "list of document IDs where the term appears. By taking the intersection of \n",
            "these sets of document IDs for all query terms, the engine determines the \n",
            "pages that contain all the key words provided by the user.  \n",
            "• Finally, the search engine presents the text content of these identified pages \n",
            "to the user, allowing them to access the relevant information they are looking \n",
            "for. This simple yet effective approach provides users with a quick and \n",
            "intuitive way to search fo r specific information within PDF documents.  \n",
            " \n",
            "Search result:\n",
            "2 | P a g e  \n",
            " \n",
            "Project 2(Two)  \n",
            "Samsung Vs Apple Comparison Module  \n",
            "Overview:  \n",
            "The Apple vs Samsung Comparison Module provides a comprehensive analysis of the performance \n",
            "and financial metrics of Apple Inc. and Samsung Electronics Co., Ltd. Users can compare various \n",
            "aspects such as revenue, net income, market capitalization, stock pr ices, and other key metrics to \n",
            "gain insights into the competitive landscape between these two technology giants.  \n",
            "Features:  \n",
            "1. Revenue Analysis:  Compare the annual revenue trends of Apple and Samsung over the \n",
            "years.  \n",
            "2. Net Income Comparison:  Analyze the net income of Apple and Samsung to understand their \n",
            "profitability.  \n",
            "3. Market Capitalization Trends:  Explore the market capitalization trends of both companies \n",
            "and how they have evolved over time.  \n",
            "4. Stock Price Comparison:  Visualize the stock price movements of Apple and Samsung and \n",
            "identify any significant trends.  \n",
            "5. Dashboard Visualization:  Present all the comparative analyses in an intuitive and user -\n",
            "friendly dashboard format for easy interpretation.  \n",
            "Usage:  \n",
            "1. Module Execution:  Run the module script or application to perform data processing, \n",
            "analysis, and visualization.  \n",
            "2. Dashboard Interaction:  Explore the dashboard interface to interact with different \n",
            "visualizations and gain insights into the comparison between Apple and Samsung.  \n",
            "3. Customization:  Modify the module parameters or dashboard layout as needed to tailor the \n",
            "analysis to specific requirements or preferences.  \n",
            "Dependencies:  \n",
            "• Python (for data processing and analysis)  \n",
            "• Pandas, Matplotlib (for data manipulation and visualization)  \n",
            "• Tableau (for dashboard creation and visualization)  \n",
            "Tableau Dashboard:  \n",
            "To access the interactive dashboard for visualizing the comparison between Apple and Samsung, \n",
            "please visit  Tableau Public  \n",
            " \n",
            " \n",
            "Search result:\n",
            "3 | P a g e  \n",
            " \n",
            "Project 3( Three)  \n",
            "Apple Stock Price Prediction using LSTM  \n",
            "This project focuses on predicting the stock prices of Apple Inc. (AAPL) using Long Short -Term \n",
            "Memory (LSTM) networks, a type of recurrent neural network (RNN). LSTM models are particularly \n",
            "effective for sequential data like stock prices due to their abili ty to capture long -term dependencies.  \n",
            "Dataset  \n",
            "The dataset used for this project consists of historical stock price data for Apple Inc.  \n",
            "Methodology  \n",
            "Data Preprocessing: The raw stock price data is preprocessed to handle missing values, normalize \n",
            "the features, and create sequential input -output pairs suitable for training LSTM models.  \n",
            "Model Training:  LSTM models are trained using the preprocessed data. The models are configured \n",
            "with appropriate hyperparameters and trained on a subset of the data. The training process involves \n",
            "optimizing the model parameters to minimize the prediction error.  \n",
            "Model Evaluation:  The trained LSTM models are evaluated using a separate test dataset to assess \n",
            "their performance in predicting future stock prices. Evaluation metrics such as mean squared error \n",
            "(MSE) or root mean squared error (RMSE) are calculated to quantify the model's  accuracy.  \n",
            "Prediction:  Once trained and evaluated, the LSTM models are used to make predictions for future \n",
            "stock prices. These predictions provide insights into potential price movements and trends, aiding \n",
            "investors in making informed decisions.  \n",
            "Repository Structure  \n",
            "• Data: 'AAPL.csv' contains the raw and preprocessed datasets used for training and testing.  \n",
            "• Notebooks: 'Apple_Stock_Price_Analysis.ipynb' contains the Jupyter notebooks with code \n",
            "for data preprocessing, model training, evaluation, and visualization.  \n",
            "• Models: Saved model checkpoints or files for the trained LSTM models.  \n",
            "• README.md: This document providing an overview of the project and instructions for \n",
            "replicating the analysis.  \n",
            "Usage  \n",
            "• Clone the repository to your local machine.  \n",
            "• Install the required dependencies and libraries.  \n",
            "• Explore the Jupyter notebooks and Python scripts to understand the data preprocessing, \n",
            "model training, and prediction process.  \n",
            "• Execute the notebooks or scripts to preprocess the data, train the LSTM models, and make \n",
            "predictions for future stock prices.  \n",
            "• Analyze the model performance using evaluation metrics and visualize the predicted stock \n",
            "prices.  \n",
            "• Experiment with different hyperparameters, architectures, or features to improve the model's accuracy.  \n",
            "Search result:\n",
            "1 | P a g e  \n",
            " \n",
            "Project 1(One ) \n",
            "FAANG Stock News Sentiment Analysis  \n",
            "Introduction  \n",
            "This project focuses on analyzing the sentiment of news articles related to FAANG (Facebook, Apple, \n",
            "Amazon, Netflix, Google) stocks. The goal is to understand the overall market sentiment surrounding \n",
            "these companies and its potential impact on stock prices . By leveraging sentiment analysis \n",
            "techniques, we aim to extract insights from textual data and identify trends and patterns in investor \n",
            "sentiment.  \n",
            "Analysis Components  \n",
            "• Data Preprocessing : Cleaning and preprocessing textual data to remove noise, such as \n",
            "stopwords, punctuation, and special characters. Tokenization and lemmatization techniques \n",
            "may also be applied to normalize the text.  \n",
            "• Sentiment Analysis : Utilizing sentiment analysis algorithms to classify news articles into \n",
            "positive, negative, or neutral sentiment categories. Techniques such as bag -of-words, TF -IDF, \n",
            "or pre -trained language models like BERT may be used for sentiment classification.  \n",
            "• Statistical Analysis : Conducting statistical tests to analyze the accuracy of the model.  \n",
            "Technologies Used  \n",
            "• Python  , Pandas , Scikit -learn  , NLTK  , Matplotlib  , Seaborn . \n",
            "Model  \n",
            "Random Forest Classifier : Random Forest is utilized as a classification model to classify sentiment \n",
            "categories based on the textual features extracted from news articles.  \n",
            "Repository Structure  \n",
            "• Dataset : 'FAANG_STOCK_NEWS_Dataset.csv' contains raw data files downloaded from Kaggle.  \n",
            "• Notebooks : 'FAANG_Stock_News_Analysis.ipynb' contains python notebook with code for data \n",
            "preprocessing , wrangling and sentiment analysis.  \n",
            "• README.md : This document providing an overview of the project, instructions, and guidelines for \n",
            "contributors.  \n",
            "Usage  \n",
            "1. Clone the repository to your local machine.  \n",
            "2. Install the required dependencies and libraries.  \n",
            "3. Explore the notebooks and scripts to understand the sentiment analysis process and run the \n",
            "code as needed.  \n",
            "4. Contribute to the project by adding new sentiment analysis techniques, improving existing \n",
            "models, or enhancing visualizations.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Samsung Vs Apple Comparison Module\" # Passing Query\n",
        "results = search_engine.search(query)\n",
        "\n",
        "for result in results: # for prints all the pages found by result running loop to fetch all the found page\n",
        "    print(\"Search result:\")\n",
        "    print(result)\n",
        "\n",
        "# Here, the search query is very specific, focusing on \"Samsung Vs Apple Comparison Module\".\n",
        "# The search engine returns only the page where all keywords are found."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laqZskeCPTKt",
        "outputId": "795474e6-5844-473f-a04b-7cb01c1fa458"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search result:\n",
            "2 | P a g e  \n",
            " \n",
            "Project 2(Two)  \n",
            "Samsung Vs Apple Comparison Module  \n",
            "Overview:  \n",
            "The Apple vs Samsung Comparison Module provides a comprehensive analysis of the performance \n",
            "and financial metrics of Apple Inc. and Samsung Electronics Co., Ltd. Users can compare various \n",
            "aspects such as revenue, net income, market capitalization, stock pr ices, and other key metrics to \n",
            "gain insights into the competitive landscape between these two technology giants.  \n",
            "Features:  \n",
            "1. Revenue Analysis:  Compare the annual revenue trends of Apple and Samsung over the \n",
            "years.  \n",
            "2. Net Income Comparison:  Analyze the net income of Apple and Samsung to understand their \n",
            "profitability.  \n",
            "3. Market Capitalization Trends:  Explore the market capitalization trends of both companies \n",
            "and how they have evolved over time.  \n",
            "4. Stock Price Comparison:  Visualize the stock price movements of Apple and Samsung and \n",
            "identify any significant trends.  \n",
            "5. Dashboard Visualization:  Present all the comparative analyses in an intuitive and user -\n",
            "friendly dashboard format for easy interpretation.  \n",
            "Usage:  \n",
            "1. Module Execution:  Run the module script or application to perform data processing, \n",
            "analysis, and visualization.  \n",
            "2. Dashboard Interaction:  Explore the dashboard interface to interact with different \n",
            "visualizations and gain insights into the comparison between Apple and Samsung.  \n",
            "3. Customization:  Modify the module parameters or dashboard layout as needed to tailor the \n",
            "analysis to specific requirements or preferences.  \n",
            "Dependencies:  \n",
            "• Python (for data processing and analysis)  \n",
            "• Pandas, Matplotlib (for data manipulation and visualization)  \n",
            "• Tableau (for dashboard creation and visualization)  \n",
            "Tableau Dashboard:  \n",
            "To access the interactive dashboard for visualizing the comparison between Apple and Samsung, \n",
            "please visit  Tableau Public  \n",
            " \n",
            " \n"
          ]
        }
      ]
    }
  ]
}